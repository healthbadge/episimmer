import matplotlib.pyplot as plt
import random
import Simulate
import ReadFile
import sys
import numpy as np
import os
import Time
sys.path.insert(1, '../src/')


class Vulnerable_Agents():
    def __init__(self):
        self.type = "Vulnerable Agents"


class Agent_Vulnerabilities():
    def __init__(self):
        self.type = "Agent Vulnerabilities"


class Agent_Vulnerabilities_MC(Agent_Vulnerabilities):
    def __init__(self, read_obj):
        super().__init__()
        self.read_obj=read_obj
        self.agent_scores={}
        self.agents_to_remove = None
        self.agent_counts = {}
        self.agent_history = {}
        self.init_scores()

    def init_scores(self):
        agents_obj=ReadFile.ReadAgents(self.read_obj.agents_filename,self.read_obj.config_obj)
        for agent_index in agents_obj.agents.keys():
            self.agent_scores[agent_index] = 0.0
            self.agent_counts[agent_index] = 0
            self.agent_history[agent_index] = []

    def remove_agents(self,agents_obj,num_agents_to_remove):
        agents = list(agents_obj.agents)
        self.agents_to_remove = random.sample(agents, num_agents_to_remove)
        for agent in self.agents_to_remove:
            agents_obj.agents.pop(agent)
            self.agent_counts[agent] += 1

    def update_agent_scores(self,end_state,states):
        agent_score = 0
        for state in states:
            agent_score += end_state[state][-1]
        total_agents = 0
        for key in end_state:
            total_agents += end_state[key][-1]
        score = 1.0 - agent_score/total_agents
        for agent in self.agents_to_remove:
            # self.agent_scores[agent] += score
            self.agent_scores[agent] += 1.0 / (self.agent_counts[agent] + 1) * (score - self.agent_scores[agent])


    def one_run(self,num_agents_to_remove, states):
        time_steps = self.read_obj.config_obj.time_steps

        Time.Time.new_world()

        # Initialize agents
        agents_obj = ReadFile.ReadAgents(self.read_obj.agents_filename, self.read_obj.config_obj)

        if(num_agents_to_remove>0):
            self.remove_agents(agents_obj,num_agents_to_remove)

        # Intialize locations
        locations_obj = ReadFile.ReadLocations(self.read_obj.locations_filename, self.read_obj.config_obj)

        # Initialize one time events
        oneTimeEvent_obj = ReadFile.ReadOneTimeEvents(self.read_obj.one_time_event_file)

        sim_obj = Simulate.Simulate(self.read_obj.config_obj, self.read_obj.model, self.read_obj.policy_list, self.read_obj.event_restriction_fn, agents_obj, locations_obj)
        sim_obj.onStartSimulation()

        for current_time_step in range(time_steps):
            sim_obj.onStartTimeStep(self.read_obj.interactions_files_list, self.read_obj.events_files_list, self.read_obj.probabilistic_interactions_files_list, oneTimeEvent_obj)
            sim_obj.handleTimeStepForAllAgents()
            sim_obj.endTimeStep()
            Time.Time.increment_current_time_step()

        end_state = sim_obj.endSimulation()
        self.update_agent_scores(end_state, states)

    def do_MC(self,num_runs,num_agents_to_remove, states):
        for i in range(num_runs):
            if i!=0 and i%(num_runs/10)==0:
                print(i)
            self.one_run(num_agents_to_remove, states)

    def get_maximum_agent_vulnerability(self,n):
        res_max = dict(sorted(self.agent_scores.items(), key = lambda x: (x[1], x[0]))[-n:])
        return res_max

    def get_minimum_agent_vulnerability(self,n):
        res_min = dict(sorted(self.agent_scores.items(), key = lambda x: (x[1], x[0]))[:n])
        return res_min


class BanditAlgos(Agent_Vulnerabilities):
    def __init__(self, read_obj, states):
        super().__init__()
        self.read_obj = read_obj
        self.states = states
        self.agent_scores = {}
        self.agents_to_remove = None
        self.agent_counts = {}
        self.eps = 0.01
        self.rm_agent = None
        self.agent_history = {}
        self.init_scores()

    def init_scores(self):
        agents_obj = ReadFile.ReadAgents(
            self.read_obj.agents_filename, self.read_obj.config_obj)
        for agent_index in agents_obj.agents.keys():
            self.agent_scores[int(agent_index)] = 1.0
            # self.agent_scores[int(agent_index)] = self.get_init_score(agent_index)
            self.agent_counts[int(agent_index)] = 0
            self.agent_history[int(agent_index)] = []

    def get_init_score(self, agent_index):

        agents_obj = ReadFile.ReadAgents(self.read_obj.agents_filename, self.read_obj.config_obj)
        agents_obj.agents.pop(agent_index)
        end_state, _, _ = self.one_run_helper(agents_obj)
        return self.get_score(end_state)

    def remove_agents(self, agents_obj):

        agents = list(agents_obj.agents)
        """
        if random.random() < self.eps:
            self.rm_agent = random.randint(0, len(agents) - 1)
        else:
            self.rm_agent = max(range(len(agents)), key=lambda x: self.agent_scores[x])
        """
        self.rm_agent = max(range(len(agents)), key=lambda x: self.agent_scores[x] + np.sqrt(2 * np.log(self.t) / (1 + self.agent_counts[x])))
        agents_obj.agents.pop(str(self.rm_agent))
        self.agent_counts[self.rm_agent] += 1

    def get_score(self, end_state):
        agent_score = 0
        for state in self.states:
            agent_score += end_state[state][-1]
        total_agents = 0
        for key in end_state:
            total_agents += end_state[key][-1]
        score = 1.0 - agent_score/total_agents
        return score

    def update_agent_scores(self, end_state):
        score = self.get_score(end_state)
        self.agent_scores[self.rm_agent] += 1.0 / (self.agent_counts[self.rm_agent] + 1) * (score - self.agent_scores[self.rm_agent])

    def one_run_helper(self, agents_obj):

        time_steps = self.read_obj.config_obj.time_steps

        Time.Time.new_world()

        # Intialize locations
        locations_obj = ReadFile.ReadLocations(self.read_obj.locations_filename, self.read_obj.config_obj)

        # Initialize one time events
        oneTimeEvent_obj = ReadFile.ReadOneTimeEvents(self.read_obj.one_time_event_file)

        sim_obj = Simulate.Simulate(self.read_obj.config_obj, self.read_obj.model, self.read_obj.policy_list, self.read_obj.event_restriction_fn, agents_obj, locations_obj)
        sim_obj.onStartSimulation()

        for current_time_step in range(time_steps):
            sim_obj.onStartTimeStep(self.read_obj.interactions_files_list, self.read_obj.events_files_list, self.read_obj.probabilistic_interactions_files_list, oneTimeEvent_obj)
            sim_obj.handleTimeStepForAllAgents()
            sim_obj.endTimeStep()
            Time.Time.increment_current_time_step()

        end_state = sim_obj.endSimulation()
        return end_state, agents_obj, locations_obj

    def one_run(self):

        agents_obj = ReadFile.ReadAgents(self.read_obj.agents_filename, self.read_obj.config_obj)
        self.remove_agents(agents_obj)
        end_state, _, _ = self.one_run_helper(agents_obj)
        self.update_agent_scores(end_state)

    def do_MC(self, num_runs):
        for i in range(num_runs):
            if i!=0 and i % (num_runs/10) == 0:
                print(i)
            self.t = i + 1
            self.one_run()

    def get_maximum_agent_vulnerability(self, n):
        res_max = dict(sorted(self.agent_scores.items(),
                       key=lambda x: (x[1], x[0]))[-n:])
        return res_max

    def get_minimum_agent_vulnerability(self, n):
        res_min = dict(sorted(self.agent_scores.items(),
                       key=lambda x: (x[1], x[0]))[:n])
        return res_min


def remove_agents(agents_obj, agents_to_remove):

    for agent in agents_to_remove:
        agents_obj.agents.pop(agent)

    return agents_obj


def plot_helper(read_obj, agents_to_remove):
    time_steps = read_obj.config_obj.time_steps
    agents_obj = ReadFile.ReadAgents(
        read_obj.agents_filename, read_obj.config_obj)
    agents_obj = remove_agents(agents_obj, agents_to_remove)

    locations_obj = ReadFile.ReadLocations(
        read_obj.locations_filename, read_obj.config_obj)

    sim_obj = Simulate.Simulate(read_obj.config_obj, read_obj.model, read_obj.policy_list,
                                read_obj.event_restriction_fn, agents_obj, locations_obj)
    sim_obj.onStartSimulation()

    for i in range(time_steps):
        if read_obj.interactions_files_list == [] or read_obj.interactions_files_list == None:
            interactions_filename = None
        else:
            interactions_filename = read_obj.interactions_files_list[i % len(
                read_obj.interactions_files_list)]
        if read_obj.events_files_list == [] or read_obj.events_files_list == None:
            events_filename = None
        else:
            events_filename = read_obj.events_files_list[i % len(
                read_obj.events_files_list)]

        sim_obj.onStartTimeStep(interactions_filename, events_filename, i)
        sim_obj.handleTimeStepForAllAgents()
        sim_obj.endTimeStep()

    end_state = sim_obj.endSimulation()
    return end_state


def plot_graph_post_removal(read_obj, agents_to_remove):

    tdict = {}
    for state in read_obj.model.individual_state_types:
        tdict[state] = [0]*(read_obj.config_obj.time_steps+1)

    for i in range(read_obj.config_obj.worlds):
        sdict = plot_helper(read_obj, agents_to_remove)
        for state in read_obj.model.individual_state_types:
            for j in range(len(tdict[state])):
                tdict[state][j] += sdict[state][j]

    for k in tdict.keys():
        l = tdict[k]
        for i in range(len(l)):
            tdict[k][i] /= read_obj.config_obj.worlds

    for state in tdict.keys():
        plt.plot(tdict[state])

    plt.title(read_obj.model.name+' plot')
    plt.legend(list(tdict.keys()), loc='upper right', shadow=True)
    plt.show()
